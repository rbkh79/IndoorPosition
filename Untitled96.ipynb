{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Cell 1: Mount Drive and Unzip Dataset"
      ],
      "metadata": {
        "id": "1U8SPow92dGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "print(\"--- Step 1: Connecting to Google Drive and Extracting Data ---\")\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- Configure Paths ---\n",
        "# Path to your ZIP file on Google Drive\n",
        "zip_file_path = '/content/drive/MyDrive/2023_IPIN_Competition_Track03.zip'\n",
        "# Destination path for extracted files in Colab\n",
        "destination_path = '/content/dataset'\n",
        "# ---\n",
        "\n",
        "# Create destination folder\n",
        "os.makedirs(destination_path, exist_ok=True)\n",
        "\n",
        "# Unzip the file quietly\n",
        "!unzip -q -o \"{zip_file_path}\" -d \"{destination_path}\"\n",
        "\n",
        "print(f\"\\nDataset successfully extracted to '{destination_path}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4OJynEb2kci",
        "outputId": "ae1f47d3-91ea-4717-9842-8d1562ca9835"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 1: Connecting to Google Drive and Extracting Data ---\n",
            "Mounted at /content/drive\n",
            "\n",
            "Dataset successfully extracted to '/content/dataset'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "CojYTYt0CQdJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- FINAL INTEGRATED BLOCK (Replaces all cells from Data Loading to PDR) ---\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import find_peaks, butter, lfilter\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "# -----------------------------------------------------------------\n",
        "# Part 1: Final, Corrected Parser and Data Loading\n",
        "# -----------------------------------------------------------------\n",
        "print(\"--- Running Final Data Loading with the Corrected Parser ---\")\n",
        "\n",
        "def parse_logfile_final_corrected(file_path):\n",
        "    \"\"\"\n",
        "    Final, corrected, and simplified parser. It extracts exactly what's needed.\n",
        "    \"\"\"\n",
        "    wifi_data, acce_data, gyro_data, magn_data = [], [], [], []\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
        "            for line in file:\n",
        "                if line.startswith('%'): continue\n",
        "                parts = [p.strip() for p in line.split(';')]\n",
        "                if not parts or not parts[0]: continue\n",
        "                data_type = parts[0]\n",
        "\n",
        "                try:\n",
        "                    if data_type == 'WIFI' and len(parts) >= 7:\n",
        "                        # Format: Type; TS1; TS2; SSID; BSSID; Freq; RSSI\n",
        "                        # We only need: Timestamp (index 2), BSSID (index 4), RSSI (index 6)\n",
        "                        wifi_data.append([parts[2], parts[4], parts[6]])\n",
        "                    elif data_type == 'ACCE' and len(parts) >= 5:\n",
        "                        # Format: Type; Timestamp; X; Y; Z\n",
        "                        acce_data.append(parts[1:5]) # [Timestamp, X, Y, Z]\n",
        "                    elif data_type == 'GYRO' and len(parts) >= 5:\n",
        "                        gyro_data.append(parts[1:5])\n",
        "                    elif data_type == 'MAGN' and len(parts) >= 5:\n",
        "                        magn_data.append(parts[1:5])\n",
        "                except IndexError: continue\n",
        "    except Exception: pass\n",
        "\n",
        "    wifi_df = pd.DataFrame(wifi_data, columns=['Timestamp', 'BSSID', 'RSSI'])\n",
        "    acce_df = pd.DataFrame(acce_data, columns=['Timestamp', 'X', 'Y', 'Z'])\n",
        "    gyro_df = pd.DataFrame(gyro_data, columns=['Timestamp', 'X', 'Y', 'Z'])\n",
        "    magn_df = pd.DataFrame(magn_data, columns=['Timestamp', 'X', 'Y', 'Z'])\n",
        "\n",
        "    # Convert all columns to numeric right away\n",
        "    for df in [wifi_df, acce_df, gyro_df, magn_df]:\n",
        "        for col in df.columns:\n",
        "            if col != 'BSSID': df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "        df.dropna(inplace=True)\n",
        "\n",
        "    return wifi_df, acce_df, gyro_df, magn_df\n",
        "\n",
        "# Load TRAINING and VALIDATION data\n",
        "training_folder_path = os.path.join('/content/dataset', '2023_IPIN_Competition_Track03', '01 Logfiles', '01 IPIN2023_T3_TrainingTrials (training)')\n",
        "validation_folder_path = os.path.join('/content/dataset', '2023_IPIN_Competition_Track03', '01 Logfiles', '02 IPIN2023_T3_TestingTrials (validation)')\n",
        "all_training_files = [os.path.join(training_folder_path, f) for f in os.listdir(training_folder_path) if f.endswith('.txt')]\n",
        "all_validation_files = [os.path.join(validation_folder_path, f) for f in os.listdir(validation_folder_path) if f.endswith('.txt')]\n",
        "\n",
        "list_of_dfs_train = [parse_logfile_final_corrected(f) for f in tqdm(all_training_files, desc=\"Processing Training Files\")]\n",
        "list_of_dfs_val = [parse_logfile_final_corrected(f) for f in tqdm(all_validation_files, desc=\"Processing Validation Files\")]\n",
        "\n",
        "# Unpack and combine all data\n",
        "combined_wifi_df = pd.concat([df[0] for df in list_of_dfs_train if not df[0].empty], ignore_index=True)\n",
        "combined_acce_df = pd.concat([df[1] for df in list_of_dfs_train if not df[1].empty], ignore_index=True)\n",
        "combined_gyro_df = pd.concat([df[2] for df in list_of_dfs_train if not df[2].empty], ignore_index=True)\n",
        "combined_magn_df = pd.concat([df[3] for df in list_of_dfs_train if not df[3].empty], ignore_index=True)\n",
        "combined_wifi_df_val = pd.concat([df[0] for df in list_of_dfs_val if not df[0].empty], ignore_index=True)\n",
        "combined_acce_df_val = pd.concat([df[1] for df in list_of_dfs_val if not df[1].empty], ignore_index=True)\n",
        "combined_gyro_df_val = pd.concat([df[2] for df in list_of_dfs_val if not df[2].empty], ignore_index=True)\n",
        "print(\"\\nAll data loaded and cleaned with the final corrected parser.\")\n",
        "\n",
        "# -----------------------------------------------------------------\n",
        "# Part 2: GT Load, Radio Map, and PDR\n",
        "# -----------------------------------------------------------------\n",
        "print(\"\\n--- Running GT Load, Radio Map, and FINAL PDR Steps ---\")\n",
        "# GT Load & Radio Map\n",
        "gt_folder_path = os.path.join('/content/dataset', '2023_IPIN_Competition_Track03', '03 Evaluation', 'GT')\n",
        "all_gt_files = [os.path.join(gt_folder_path, f) for f in os.listdir(gt_folder_path) if f.endswith('.csv')]\n",
        "gt_df_sorted = pd.concat([pd.read_csv(f, header=None, usecols=[0,1,2,3], names=['Timestamp','X','Y','Floor']) for f in all_gt_files], ignore_index=True).sort_values('Timestamp')\n",
        "synchronized_df = pd.merge_asof(combined_wifi_df.sort_values('Timestamp'), gt_df_sorted, on='Timestamp', direction='nearest', tolerance=500).dropna(subset=['X','Y'])\n",
        "radio_map = synchronized_df.pivot_table(index=['Timestamp','X','Y','Floor'], columns='BSSID', values='RSSI').fillna(-100).reset_index()\n",
        "radio_map_features_only = radio_map.drop(columns=['Timestamp','X','Y','Floor'])\n",
        "\n",
        "# --- PDR on a single validation trial ---\n",
        "trial_to_test = 0\n",
        "file_to_test = all_validation_files[trial_to_test]\n",
        "print(f\"\\nSelecting test path from: {os.path.basename(file_to_test)}\")\n",
        "wifi_val_single, acce_val_single, gyro_val_single, _ = parse_logfile_final_corrected(file_to_test)\n",
        "\n",
        "# Gravity Removal\n",
        "fs = 50; cutoff = 0.5; order = 2\n",
        "nyq = 0.5 * fs; normal_cutoff = cutoff / nyq\n",
        "b, a = butter(order, normal_cutoff, btype='high', analog=False)\n",
        "acc_x_filtered = lfilter(b, a, acce_val_single['X']); acc_y_filtered = lfilter(b, a, acce_val_single['Y']); acc_z_filtered = lfilter(b, a, acce_val_single['Z'])\n",
        "accel_mag = np.sqrt(acc_x_filtered**2 + acc_y_filtered**2 + acc_z_filtered**2)\n",
        "accel_mag_smooth = pd.Series(accel_mag).rolling(5, center=True).mean().bfill().ffill()\n",
        "\n",
        "# Plot the real, gravity-removed acceleration signal\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.plot(accel_mag_smooth, label='Gravity-Removed Acceleration Magnitude')\n",
        "plt.title('FINAL Corrected Acceleration Signal (Gravity Removed)')\n",
        "plt.xlabel('Sample Index'); plt.ylabel('Magnitude (m/s^2)'); plt.grid(True); plt.legend(); plt.show()\n",
        "\n",
        "# Find Peaks\n",
        "height_threshold = 1.5\n",
        "peaks, _ = find_peaks(accel_mag_smooth, height=height_threshold, distance=20)\n",
        "print(f\"\\nFINAL PDR step detection. Steps detected: {len(peaks)}\")\n",
        "\n",
        "# Path Reconstruction\n",
        "path_x, path_y = [0.0], [0.0]\n",
        "if len(peaks) > 0:\n",
        "    headings_simple = []\n",
        "    current_heading = 0.0\n",
        "    for i in range(len(peaks) - 1):\n",
        "        start_time = acce_val_single['Timestamp'].iloc[peaks[i]]\n",
        "        end_time = acce_val_single['Timestamp'].iloc[peaks[i+1]]\n",
        "        gyro_segment = gyro_val_single[(gyro_val_single['Timestamp'] >= start_time) & (gyro_val_single['Timestamp'] < end_time)]\n",
        "        if not gyro_segment.empty:\n",
        "            timestamps = gyro_segment['Timestamp'].values\n",
        "            dt_gyro = np.diff(timestamps, prepend=timestamps[0]) / 1000.0\n",
        "            angle_change = np.sum(gyro_segment['Z'].values * dt_gyro)\n",
        "            current_heading += angle_change\n",
        "    headings_simple.append(current_heading)\n",
        "    headings_simple.insert(0, 0.0)\n",
        "    for i in range(len(headings_simple)):\n",
        "        path_x.append(path_x[-1] + 0.65 * np.cos(headings_simple[i])); path_y.append(path_y[-1] + 0.65 * np.sin(headings_simple[i]))\n",
        "\n",
        "def predict_position_knn(live_scan, radio_map_features, k=5):\n",
        "    distances = np.linalg.norm(radio_map_features.values - live_scan, axis=1)\n",
        "    k_indices = np.argsort(distances)[:k]; k_locations = radio_map.iloc[k_indices][['X', 'Y']]\n",
        "    return k_locations.mean().values, k_locations.values\n",
        "print(\"\\nAll prerequisites are now complete.\")\n",
        "# Save necessary variables for the next steps\n",
        "wifi_scans_for_trial = wifi_val_single.copy(); acce_df_single_trial = acce_val_single.copy()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "id": "n1o3qAoOCRMf",
        "outputId": "68c242b8-08fa-466e-b3da-247bfaaeaf65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cell 7: Implement and Run the Simple Kalman Filter"
      ],
      "metadata": {
        "id": "QMv2OphR5fTl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7 (Corrected): Implement and Run the STABLE Simple Kalman Filter\n",
        "print(\"\\n--- Step 7: Running the STABLE Simple Kalman Filter ---\")\n",
        "\n",
        "# KF matrices and variables\n",
        "x_kf = np.array([0.0, 0.0]); P_kf = np.diag([1.0, 1.0]) # Start with reasonable uncertainty\n",
        "F = np.eye(2); H = np.eye(2); I = np.eye(2)\n",
        "Q = np.diag([0.1, 0.1]); R_simple = np.diag([5.0, 5.0]) # Initial Q and R\n",
        "kalman_path = [x_kf.copy()]\n",
        "\n",
        "for i in tqdm(range(1, len(path_x)), desc=\"Running Simple KF\"):\n",
        "    dx = path_x[i] - path_x[i-1]; dy = path_y[i] - path_y[i-1]\n",
        "    u = np.array([dx, dy]); x_pred = F @ x_kf + u;\n",
        "\n",
        "    # --- STABILITY FIX ---\n",
        "    # Ensure P_pred doesn't become zero\n",
        "    P_pred = F @ P_kf @ F.T + Q\n",
        "    P_pred = P_pred + 1e-6 * I # Add a small identity matrix for numerical stability\n",
        "    # -------------------\n",
        "\n",
        "    current_time = acce_df_single_trial['Timestamp'].iloc[peaks[i-1]]\n",
        "    time_diff = np.abs(wifi_scans_for_trial['Timestamp'] - current_time)\n",
        "    if not time_diff.empty:\n",
        "        closest_scan_idx = time_diff.idxmin()\n",
        "        scan_group = wifi_scans_for_trial[wifi_scans_for_trial['Timestamp'] == wifi_scans_for_trial.loc[closest_scan_idx, 'Timestamp']]\n",
        "        live_rssi_vector = pd.Series(index=radio_map_features_only.columns, data=-100)\n",
        "        live_rssi_vector.loc[scan_group['BSSID'].values] = scan_group['RSSI'].values\n",
        "        z, _ = predict_position_knn(live_rssi_vector.values, radio_map_features_only, k=5)\n",
        "\n",
        "        y = z - H @ x_pred\n",
        "        S = H @ P_pred @ H.T + R_simple\n",
        "\n",
        "        # --- STABILITY FIX ---\n",
        "        # Use pseudo-inverse (pinv) which is robust to singular matrices\n",
        "        K = P_pred @ H.T @ np.linalg.pinv(S)\n",
        "        # -------------------\n",
        "\n",
        "        x_kf = x_pred + K @ y; P_kf = (I - K @ H) @ P_pred\n",
        "    else:\n",
        "        x_kf = x_pred; P_kf = P_pred\n",
        "    kalman_path.append(x_kf.copy())\n",
        "kalman_path = np.array(kalman_path)\n",
        "print(\"Stable Simple KF fusion complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "qNyFjSjJJ_vg",
        "outputId": "9a3beeb2-aefe-48d4-bae5-f336d7508b2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cell 8 (Corrected): Tune STABLE Simple Kalman Filter Parameters"
      ],
      "metadata": {
        "id": "XCAo_NREKCky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8 (Corrected): Tune STABLE Simple Kalman Filter Parameters\n",
        "from scipy.spatial.distance import euclidean\n",
        "\n",
        "print(\"\\n--- Step 8: Tuning the STABLE Simple Kalman Filter ---\")\n",
        "\n",
        "q_values = [0.01, 0.1, 0.5, 1.0]; r_values = [1, 5, 10, 20, 50]\n",
        "tuning_results = []\n",
        "\n",
        "def calculate_rmse(eval_df, pred_cols, true_cols):\n",
        "    if eval_df.empty: return 0.0, []\n",
        "    pred_points = eval_df[pred_cols].values; true_points = eval_df[true_cols].values\n",
        "    errors = np.linalg.norm(pred_points - true_points, axis=1)\n",
        "    return np.sqrt(np.mean(errors**2)), errors\n",
        "\n",
        "for q_val in q_values:\n",
        "    for r_val in r_values:\n",
        "        Q = np.diag([q_val, q_val]); R = np.diag([r_val, r_val])\n",
        "        x_kf_tuned = np.array([0.0, 0.0]); P_kf_tuned = np.diag([1.0, 1.0])\n",
        "        kalman_path_tuned = [x_kf_tuned.copy()]\n",
        "        for i in range(1, len(path_x)):\n",
        "            dx = path_x[i] - path_x[i-1]; dy = path_y[i] - path_y[i-1]\n",
        "            u = np.array([dx, dy]); x_pred = F @ x_kf_tuned + u\n",
        "            P_pred = F @ P_kf_tuned @ F.T + Q + 1e-6 * I\n",
        "            current_time = acce_df_single_trial['Timestamp'].iloc[peaks[i-1]]\n",
        "            time_diff = np.abs(wifi_scans_for_trial['Timestamp'] - current_time)\n",
        "            if not time_diff.empty:\n",
        "                closest_scan_idx = time_diff.idxmin()\n",
        "                scan_group = wifi_scans_for_trial[wifi_scans_for_trial['Timestamp'] == wifi_scans_for_trial.loc[closest_scan_idx, 'Timestamp']]\n",
        "                live_rssi_vector = pd.Series(index=radio_map_features_only.columns, data=-100)\n",
        "                live_rssi_vector.loc[scan_group['BSSID'].values] = scan_group['RSSI'].values\n",
        "                z, _ = predict_position_knn(live_rssi_vector.values, radio_map_features_only, k=5)\n",
        "                y = z - H @ x_pred; S = H @ P_pred @ H.T + R\n",
        "                K = P_pred @ H.T @ np.linalg.pinv(S) # Use pinv\n",
        "                x_kf_tuned = x_pred + K @ y; P_kf_tuned = (I - K @ H) @ P_pred\n",
        "            else:\n",
        "                x_kf_tuned = x_pred; P_kf_tuned = P_pred\n",
        "            kalman_path_tuned.append(x_kf_tuned.copy())\n",
        "        kalman_path_tuned = np.array(kalman_path_tuned)\n",
        "\n",
        "        path_timestamps = np.insert(acce_df_single_trial['Timestamp'].iloc[peaks].values, 0, acce_df_single_trial['Timestamp'].iloc[0])\n",
        "        min_len = min(len(path_timestamps), len(kalman_path_tuned))\n",
        "        path_timestamps_tuned = path_timestamps[:min_len]; kalman_path_tuned = kalman_path_tuned[:min_len]\n",
        "        kf_tuned_df = pd.DataFrame({'Timestamp': path_timestamps_tuned, 'x': kalman_path_tuned[:, 0], 'y': kalman_path_tuned[:, 1]})\n",
        "        eval_kf_tuned_df = pd.merge_asof(kf_tuned_df.sort_values('Timestamp'), gt_df_sorted, on='Timestamp', direction='nearest', tolerance=1000).dropna()\n",
        "        rmse, _ = calculate_rmse(eval_kf_tuned_df, pred_cols=['x', 'y'], true_cols=['X', 'Y'])\n",
        "        tuning_results.append({'q': q_val, 'r': r_val, 'rmse': rmse})\n",
        "\n",
        "best_result = min(tuning_results, key=lambda x: x['rmse'])\n",
        "best_baseline_rmse = best_result['rmse']\n",
        "best_Q = np.diag([best_result['q'], best_result['q']])\n",
        "best_R = np.diag([best_result['r'], best_result['r']])\n",
        "print(f\"\\nBest Tuned Simple KF RMSE: {best_baseline_rmse:.2f} meters (with Q={best_result['q']}, R={best_result['r']})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFIV-9doKVlL",
        "outputId": "a481ae13-cc10-4eec-94ba-228306bfeb9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cell 9 (Corrected): Train GPR model to predict k-NN error"
      ],
      "metadata": {
        "id": "oieUXpbvLAIg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9 (Corrected): Train GPR model to predict k-NN error\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF, WhiteKernel\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "print(\"\\n--- Step 9: Training the GPR model ---\")\n",
        "\n",
        "# --- Create the feature set for GPR ---\n",
        "feature_df = pd.DataFrame(index=radio_map.index)\n",
        "# ... (The rest of the feature engineering part is the same, just ensure it's run)\n",
        "feature_df['rssi_mean'] = radio_map_features_only.replace(-100, np.nan).mean(axis=1)\n",
        "feature_df['rssi_std'] = radio_map_features_only.replace(-100, np.nan).std(axis=1)\n",
        "feature_df['num_aps_heard'] = (radio_map_features_only != -100).sum(axis=1)\n",
        "knn_errors = []; neighbor_distances = []; neighbor_position_variances = []\n",
        "radio_map_labels_only = radio_map[['X', 'Y']]\n",
        "for i in tqdm(range(len(radio_map)), desc=\"Engineering GPR Features\"):\n",
        "    live_scan = radio_map_features_only.iloc[i].values\n",
        "    actual_pos = radio_map_labels_only.iloc[i].values\n",
        "    temp_map_features = radio_map_features_only.drop(index=i); temp_map_labels = radio_map_labels_only.drop(index=i)\n",
        "    distances = np.linalg.norm(temp_map_features.values - live_scan, axis=1)\n",
        "    k_indices = np.argsort(distances)[:5]\n",
        "    neighbor_distances.append(distances[k_indices[0]])\n",
        "    k_locations = temp_map_labels.iloc[k_indices]\n",
        "    neighbor_position_variances.append(np.var(k_locations.values))\n",
        "    predicted_pos, _ = predict_position_knn(live_scan, temp_map_features, k=5)\n",
        "    knn_errors.append(euclidean(actual_pos, predicted_pos))\n",
        "feature_df['knn_error'] = knn_errors; feature_df['neighbor_dist'] = neighbor_distances\n",
        "feature_df['neighbor_pos_var'] = neighbor_position_variances; feature_df.fillna(0, inplace=True)\n",
        "# ---\n",
        "\n",
        "X_gpr = feature_df[['rssi_mean', 'rssi_std', 'num_aps_heard', 'neighbor_dist', 'neighbor_pos_var']]\n",
        "y_gpr = feature_df['knn_error']\n",
        "gpr_scaler = StandardScaler().fit(X_gpr)\n",
        "X_gpr_scaled = gpr_scaler.transform(X_gpr)\n",
        "kernel = 1.0 * RBF() + WhiteKernel()\n",
        "gpr_model = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9, random_state=42)\n",
        "print(\"Training GPR... (This might take a while)\")\n",
        "gpr_model.fit(X_gpr_scaled, y_gpr)\n",
        "print(\"GPR model training complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "dLK0OoJZLB-W",
        "outputId": "bce2e84a-2ccf-4f15-b98c-89a8a14732ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cell 10 (Corrected): Run the STABLE GPR-based Adaptive Kalman Filter (GP-AKF)"
      ],
      "metadata": {
        "id": "PmSnZm3AL_LH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 10 (Corrected): Run the STABLE GPR-based Adaptive Kalman Filter (GP-AKF)\n",
        "print(\"\\n--- Step 10: Running the STABLE GP-AKF ---\")\n",
        "\n",
        "x_gp_akf = np.array([0.0, 0.0]); P_gp_akf = np.diag([1.0, 1.0])\n",
        "kalman_path_gp_akf = [x_gp_akf.copy()]\n",
        "\n",
        "for i in tqdm(range(1, len(path_x)), desc=\"Running GP-AKF\"):\n",
        "    dx = path_x[i] - path_x[i-1]; dy = path_y[i] - path_y[i-1]\n",
        "    u = np.array([dx, dy]); x_pred = F @ x_gp_akf + u; P_pred = F @ P_gp_akf @ F.T + best_Q + 1e-6 * I\n",
        "    current_time = acce_df_single_trial['Timestamp'].iloc[peaks[i-1]]\n",
        "    time_diff = np.abs(wifi_scans_for_trial['Timestamp'] - current_time)\n",
        "    if not time_diff.empty:\n",
        "        closest_scan_idx = time_diff.idxmin()\n",
        "        # ... (code to get live_features_scaled is the same)\n",
        "        scan_group = wifi_scans_for_trial[wifi_scans_for_trial['Timestamp'] == wifi_scans_for_trial.loc[closest_scan_idx, 'Timestamp']]\n",
        "        live_rssi_vector = pd.Series(index=radio_map_features_only.columns, data=-100)\n",
        "        live_rssi_vector.loc[scan_group['BSSID'].values] = scan_group['RSSI'].values\n",
        "        live_scan_np = live_rssi_vector.values\n",
        "        rssi_mean = np.mean(live_scan_np[live_scan_np != -100]); rssi_std = np.std(live_scan_np[live_scan_np != -100])\n",
        "        num_aps_heard = np.sum(live_scan_np != -100)\n",
        "        distances = np.linalg.norm(radio_map_features_only.values - live_scan_np, axis=1)\n",
        "        k_indices = np.argsort(distances)[:5]; neighbor_dist = distances[k_indices[0]]\n",
        "        k_locations = radio_map.iloc[k_indices][['X', 'Y']]; neighbor_pos_var = np.var(k_locations.values)\n",
        "        live_features = [rssi_mean, rssi_std, num_aps_heard, neighbor_dist, neighbor_pos_var]\n",
        "        live_features_np = np.nan_to_num(np.array(live_features).reshape(1, -1))\n",
        "        live_features_scaled = gpr_scaler.transform(live_features_np)\n",
        "\n",
        "        _, predicted_std = gpr_model.predict(live_features_scaled, return_std=True)\n",
        "        predicted_variance = predicted_std[0]**2\n",
        "        r_val = predicted_variance + 1.0\n",
        "        R_adaptive = np.diag([r_val, r_val])\n",
        "\n",
        "        z, _ = predict_position_knn(live_scan_np, radio_map_features_only, k=5)\n",
        "        y = z - H @ x_pred; S = H @ P_pred @ H.T + R_adaptive\n",
        "        K = P_pred @ H.T @ np.linalg.pinv(S) # Use pinv\n",
        "        x_gp_akf = x_pred + K @ y; P_gp_akf = (I - K @ H) @ P_pred\n",
        "    else:\n",
        "        x_gp_akf = x_pred; P_gp_akf = P_pred\n",
        "    kalman_path_gp_akf.append(x_gp_akf.copy())\n",
        "kalman_path_gp_akf = np.array(kalman_path_gp_akf)\n",
        "print(\"Stable GP-AKF fusion complete.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "RJoX06hdMAkh",
        "outputId": "34ec6f5c-1cf7-4a3a-b7f7-605d25d73050"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cell 11 (Corrected): Run the STABLE Correntropy-based Robust Kalman Filter (MCKF)"
      ],
      "metadata": {
        "id": "8zheYquhMSnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cell 11 (Corrected): Run the STABLE Correntropy-based Robust Kalman Filter (MCKF)\n",
        "print(\"\\n--- Step 11: Running the STABLE MCKF ---\")\n",
        "\n",
        "x_mckf = np.array([0.0, 0.0]); P_mckf = np.diag([1.0, 1.0])\n",
        "kernel_sigma = 5.0\n",
        "kalman_path_mckf = [x_mckf.copy()]\n",
        "\n",
        "for i in tqdm(range(1, len(path_x)), desc=\"Running MCKF\"):\n",
        "    dx = path_x[i] - path_x[i-1]; dy = path_y[i] - path_y[i-1]\n",
        "    u = np.array([dx, dy]); x_pred = F @ x_mckf + u; P_pred = F @ P_mckf @ F.T + best_Q + 1e-6 * I\n",
        "    current_time = acce_df_single_trial['Timestamp'].iloc[peaks[i-1]]\n",
        "    time_diff = np.abs(wifi_scans_for_trial['Timestamp'] - current_time)\n",
        "    if not time_diff.empty:\n",
        "        closest_scan_idx = time_diff.idxmin()\n",
        "        scan_group = wifi_scans_for_trial[wifi_scans_for_trial['Timestamp'] == wifi_scans_for_trial.loc[closest_scan_idx, 'Timestamp']]\n",
        "        live_rssi_vector = pd.Series(index=radio_map_features_only.columns, data=-100)\n",
        "        live_rssi_vector.loc[scan_group['BSSID'].values] = scan_group['RSSI'].values\n",
        "        z, _ = predict_position_knn(live_rssi_vector.values, radio_map_features_only, k=5)\n",
        "\n",
        "        S_inv = np.linalg.pinv(H @ P_pred @ H.T + best_R) # Use pinv\n",
        "        innovation = z - H @ x_pred\n",
        "        mahalanobis_sq = innovation.T @ S_inv @ innovation\n",
        "        correntropy_weight = np.exp(-0.5 * mahalanobis_sq / (kernel_sigma**2))\n",
        "        R_robust = best_R / (correntropy_weight + 1e-6)\n",
        "\n",
        "        S = H @ P_pred @ H.T + R_robust\n",
        "        K = P_pred @ H.T @ np.linalg.pinv(S) # Use pinv\n",
        "        x_mckf = x_pred + K @ innovation; P_mckf = (I - K @ H) @ P_pred\n",
        "    else:\n",
        "        x_mckf = x_pred; P_mckf = P_pred\n",
        "    kalman_path_mckf.append(x_mckf.copy())\n",
        "kalman_path_mckf = np.array(kalman_path_mckf)\n",
        "print(\"Stable MCKF fusion complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "nl0qqKwJMTil",
        "outputId": "70816703-08ab-40b7-f706-ac41c61f7a66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4Gr31mtuMh8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 12: Final Comprehensive Evaluation and Visualization\n",
        "print(\"\\n--- Step 12: Final Comprehensive Evaluation ---\")\n",
        "\n",
        "# Calculate RMSE for GP-AKF\n",
        "min_len = min(len(path_timestamps), len(kalman_path_gp_akf))\n",
        "kf_gp_akf_df = pd.DataFrame({'Timestamp': path_timestamps[:min_len], 'x': kalman_path_gp_akf[:min_len, 0], 'y': kalman_path_gp_akf[:min_len, 1]})\n",
        "eval_gp_akf_df = pd.merge_asof(kf_gp_akf_df.sort_values('Timestamp'), gt_df_sorted, on='Timestamp', direction='nearest', tolerance=1000).dropna()\n",
        "gp_akf_rmse, _ = calculate_rmse(eval_gp_akf_df, pred_cols=['x', 'y'], true_cols=['X', 'Y'])\n",
        "\n",
        "# Calculate RMSE for MCKF\n",
        "min_len = min(len(path_timestamps), len(kalman_path_mckf))\n",
        "kf_mckf_df = pd.DataFrame({'Timestamp': path_timestamps[:min_len], 'x': kalman_path_mckf[:min_len, 0], 'y': kalman_path_mckf[:min_len, 1]})\n",
        "eval_mckf_df = pd.merge_asof(kf_mckf_df.sort_values('Timestamp'), gt_df_sorted, on='Timestamp', direction='nearest', tolerance=1000).dropna()\n",
        "mckf_rmse, _ = calculate_rmse(eval_mckf_df, pred_cols=['x', 'y'], true_cols=['X', 'Y'])\n",
        "\n",
        "print(\"\\n--- FINAL OVERALL RESULTS (Advanced Methods) ---\")\n",
        "print(f\"Optimized Simple KF RMSE (Baseline):     {best_baseline_rmse:.2f} meters\")\n",
        "print(f\"GPR-based Adaptive KF (GP-AKF) RMSE:   {gp_akf_rmse:.2f} meters\")\n",
        "print(f\"Correntropy-based Robust KF (MCKF) RMSE: {mckf_rmse:.2f} meters\")\n",
        "print(\"-\" * 50)\n",
        "imp_gp = ((best_baseline_rmse - gp_akf_rmse) / best_baseline_rmse) * 100\n",
        "imp_mc = ((best_baseline_rmse - mckf_rmse) / best_baseline_rmse) * 100\n",
        "print(f\"Improvement of GP-AKF over Baseline: {imp_gp:.2f}%\")\n",
        "print(f\"Improvement of MCKF over Baseline:   {imp_mc:.2f}%\")\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "plt.plot(gt_df_sorted['Y'], gt_df_sorted['X'], 'b-', label='Ground Truth Path', linewidth=5, alpha=0.3)\n",
        "plt.plot(kalman_path[:, 1], kalman_path[:, 0], 'grey', linestyle='--', label=f'Baseline KF (RMSE: {best_baseline_rmse:.2f}m)')\n",
        "plt.plot(kalman_path_gp_akf[:, 1], kalman_path_gp_akf[:, 0], 'g-^', markersize=4, label=f'GP-Adaptive KF (RMSE: {gp_akf_rmse:.2f}m)')\n",
        "plt.plot(kalman_path_mckf[:, 1], kalman_path_mckf[:, 0], 'r-o', markersize=4, label=f'Correntropy KF (RMSE: {mckf_rmse:.2f}m)')\n",
        "plt.title('Final Comparison: Baseline vs. Advanced Kalman Filters')\n",
        "plt.xlabel('Y Position (meters)'); plt.ylabel('X Position (meters)')\n",
        "plt.legend(); plt.grid(True); plt.axis('equal'); plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "I3V0oECzMjCw",
        "outputId": "b9b9a17a-bcfd-44c2-f911-503545d823a6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
--- END OF FILE ---
